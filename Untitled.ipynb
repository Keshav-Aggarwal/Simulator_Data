{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import glob\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('800.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhist = np.histogram(img[:, :, 0], bins = 32, range=(0,255))\n",
    "ghist = np.histogram(img[:, :, 1], bins = 32, range=(0,255))\n",
    "bhist = np.histogram(img[:, :, 2], bins = 32, range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 32 artists>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22326a4c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_edges = rhist[1]\n",
    "rbin_centers = (bin_edges[1:] + bin_edges[:len(bin_edges)-1])/2\n",
    "plt.bar(rbin_centers, rhist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_features = np.concatenate([rhist, ghist, bhist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogR(img,pix_per_cell = 9, cell_per_block = 2, orient = 9):\n",
    "    hg, hgimg = hog(img, orientations=orient,pixels_per_cell=(pix_per_cell, pix_per_cell), cells_per_block=(cell_per_block, cell_per_block), visualise=True, feature_vector=False,\n",
    "                          block_norm=\"L2-Hys\" )\n",
    "    return hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "        \n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedScene(img, window):\n",
    "    p1 = window[0]\n",
    "    p2 = window[1]\n",
    "    return img[p1[0]:p2[0], p1[1]:p2[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTest = plt.imread('test5.jpg')\n",
    "windows = slide_window(imgTest, x_start_stop=[None, None], y_start_stop=[400, None],xy_window=(64, 64), xy_overlap=(0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehiclesDir = os.listdir('vehicles')\n",
    "imagesVehiclePath = []\n",
    "for folder in vehiclesDir:\n",
    "    path = os.path.join(os.path.join('vehicles',folder), '*.png')\n",
    "    imagesVehiclePath.append(glob.glob(path))\n",
    "    \n",
    "nonVehiclesDir = os.listdir('non-vehicles')\n",
    "nonImagesVehiclePath = []\n",
    "for folder in nonVehiclesDir:\n",
    "    path = os.path.join(os.path.join('non-vehicles',folder), '*.png')\n",
    "    nonImagesVehiclePath.append(glob.glob(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = []\n",
    "nonVehicle = []\n",
    "for imgDirPath in imagesVehiclePath:\n",
    "    for imgPath in imgDirPath:\n",
    "        vehicle.append(plt.imread(imgPath))\n",
    "\n",
    "for imgDirPath in nonImagesVehiclePath:\n",
    "    for imgPath in imgDirPath:\n",
    "        nonVehicle.append(plt.imread(imgPath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vehicle Data samples  8792\n",
      "Number of Non-Vehicle Data samples  8968\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Vehicle Data samples \", len(vehicle))\n",
    "print(\"Number of Non-Vehicle Data samples \", len(nonVehicle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_class = ['Cars','Not Car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_vehicle = [y_label_class[0]]*len(vehicle)\n",
    "y_label_nonVehicle = [y_label_class[1]]*len(nonVehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([vehicle, nonVehicle])\n",
    "label = np.hstack([y_label_vehicle, y_label_nonVehicle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessData(data):\n",
    "    hogFeaturesR = []\n",
    "    for img in data:\n",
    "        tempData = []\n",
    "        for i in range(3):\n",
    "            tempData.append(hogR(img[:,:,i]))\n",
    "        \n",
    "        hogFeaturesR.append(np.vstack(tempData))\n",
    "    sampleHog = np.array(hogFeaturesR)\n",
    "    sampleHog = (sampleHog.reshape((len(sampleHog),-1)))\n",
    "    return sampleHog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleHog = preProcessData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 3888)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleHog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampleHog, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14208, 50)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "parameters = {'C':[1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = SVC()\n",
    "clf = grid_search.GridSearchCV(classifier, parameters,cv=5) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 209, 1609],\n",
       "       [   0, 1734]], dtype=int64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54701576576576572"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class PipelineComplete(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preProcessData(self, data):\n",
    "        hogFeaturesR = []\n",
    "        for img in data:\n",
    "            tempData = []\n",
    "            for i in range(3):\n",
    "                tempData.append(hogR(img[:,:,i]))\n",
    "\n",
    "            hogFeaturesR.append(np.vstack(tempData))\n",
    "        sampleHog = np.array(hogFeaturesR)\n",
    "        sampleHog = (sampleHog.reshape((len(sampleHog),-1)))\n",
    "        return sampleHog\n",
    "\n",
    "    def transform(self, x, y= None):\n",
    "        return preProcessData(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
